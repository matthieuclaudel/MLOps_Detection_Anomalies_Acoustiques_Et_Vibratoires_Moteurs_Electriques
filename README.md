DÃ©tection des anomalies acoustiques et vibratoires des moteurs Ã©lectriques
==============================
ğŸ¯ Ce projet vise Ã  automatiser la dÃ©tection d'anomalies acoustiques et vibratoires sur des moteurs Ã©lectriques Ã  la sortie d'une chaÃ®ne de production. L'objectif final est d'assurer un contrÃ´le qualitÃ© prÃ©cis et fiable tout en rÃ©duisant les coÃ»ts et les temps d'inspection. ğŸš€

## Equipe projet

- Ludovic ANDRIEUX [GitHub](https://github.com/ludodo23)
- Matthieu CLAUDEL ([GitHub](https://github.com/matthieuclaudel) / [LinkedIn](http://www.linkedin.com/in/matthieu-claudel-8a927857))
- Adrien PINEL [GitHub](https://github.com/Adriencalvados) / [LinkedIn](www.linkedin.com/in/adrien-pinel-machine-learning-ingenieur)
- Harold MOUKALA MITATI [GitHub](https://github.com/Ngulumanua)

## Architecture de l'application

![Architecture](./data/Archi.png)

## Table des MatiÃ¨res

1. [Installation](#installation)
2. [Utilisation](#utilisation)
3. [Conteneurs Docker](#conteneurs-docker)
4. [PrÃ©requis](#prÃ©requis)
5. [Installation Kubernetes](#installation-kubernetes)
6. [Orchestration et Charts Helm](#orchestration-et-charts-helm)
7. [Ã‰valuation et Surveillance](#Ã©valuation-et-surveillance)
8. [Pods CrÃ©Ã©s](#pods-crÃ©Ã©s)
9. [Architecture Globale](#architecture-globale)
10. [Contributions](#contributions)
11. [Licence](#licence)
12. [Remerciements](#remerciements)
13. [RÃ©pertoires](#Repository-Tree)
14. [Configuration des Redirections avec Traefik](#Bonus-:-configuration-des-redirections-avec-traefik)
---

## Installation

### Ã‰tapes d'installation

ğŸ”§ **Cloner le dÃ©pÃ´t GitHub :**

```bash
git clone https://github.com/matthieuclaudel/MLOps_Detection_Anomalies_Acoustiques_Et_Vibratoires_Moteurs_Electriques.git
```

ğŸ’» **Naviguer dans le rÃ©pertoire du projet :**

```bash
cd MLOps_Detection_Anomalies_Acoustiques_Et_Vibratoires_Moteurs_Electriques
```

ğŸ› ï¸ **CrÃ©er et activer un environnement virtuel Python :**

```bash
python3 -m venv venv
source venv/bin/activate
```

ğŸ“¦ **Installer les dÃ©pendances :**

```bash
pip install -r requirements.txt
```

---

## Utilisation

1. **Activer l'environnement virtuel :**

```bash
source venv/bin/activate
```

2. **Lancer l'application :**

```bash
python main.py
```

âš™ï¸ Fonction principale : Lors de son exÃ©cution, le script main.py rÃ©cupÃ¨re les donnÃ©es depuis DVC, crÃ©e les ensembles X_test, X_train, Y_test, et Y_train dans les dossiers data, applique une transformation avec un standard scaler, entraÃ®ne un modÃ¨le, et le stocke dans Dagshub (MLflow Cloud). ğŸš€

---

## Conteneurs Docker

### Conteneurs disponibles

ğŸš¢ **CrÃ©er un rÃ©seau de bridge :**

```bash
docker network create bridge_test_container
```

ğŸ› ï¸ **API FastAPI (root URL : /api) :**

```bash
docker build -t adrien157/api -f docker/dockerfile.app_model .
docker push adrien157/api:latest
docker run --rm --name api --env-file .env -p 30001:30001 --network bridge_test_container adrien157/api:latest
```
![Architecture fastapi](./images/Diagramme-2025-01-06-2022.png)
ğŸŒ **Simulation de requÃªtes :**

```bash
docker build -t adrien157/simulation_request_model -f docker/dockerfile.app_simu .
docker push adrien157/simulation_request_model:latest
docker run --rm --name simu_request --env-file .env --network bridge_test_container adrien157/simulation_request_model:latest
```

ğŸ“Š **Application Streamlit :**

```bash
docker build -t adrien157/app_streamlit -f docker/dockerfile.app_streamlit .
docker push adrien157/app_streamlit:latest
docker run --rm --name app_streamlit --env-file .env -p 8501:8501 --network bridge_test_container adrien157/app_streamlit:latest
```

---

## PrÃ©requis

Pour utiliser ce projet, vous aurez besoin de :

- Un compte [DagsHub](https://dagshub.com/) ğŸ–¥ï¸
- Un compte [Docker](https://www.docker.com/) ğŸ³
- Une machine avec Debian installÃ© ğŸ–§
- Kubernetes K3S installÃ© â˜¸ï¸

---

## Installation Kubernetes

### Ã‰tapes d'installation avec Helm

ğŸ”¨ **Installer Helm :**

```bash
curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
```

ğŸ“‹ **Configurer Kubernetes avec K3S :**

```bash
curl -sfL https://get.k3s.io | sh -
```

## Orchestration et Charts Helm

ğŸ“ˆ **Prometheus Stack :**

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm install my-kube-prometheus-stack prometheus-community/kube-prometheus-stack --version 66.3.1
```

âœˆï¸ **Apache Airflow :**

```bash
helm repo add apache-airflow https://airflow.apache.org/
helm repo update
helm install my-airflow apache-airflow/airflow --version 1.15.0
```

**DÃ©ploiement de MongoDB (port 27017)**

Pour dÃ©ployer MongoDB et Mongo Express avec Helm, utilisez les commandes suivantesÂ :

```bash
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo add cowboysysop https://cowboysysop.github.io/charts/
helm repo update
helm install my-mongodb bitnami/mongodb --version 16.3.3 -f kubernetes/values-mongodb.yaml
helm install my-mongo-express cowboysysop/mongo-express --version 6.5.2 -f kubernetes/values-mongo-express.yaml
helm upgrade my-mongo-express cowboysysop/mongo-express --version 6.5.2 -f kubernetes/values-mongo-express.yaml
```

MongoDB est configurÃ© pour fonctionner avec les valeurs dÃ©finies dans le fichier `values-mongodb.yaml`.

## Ã‰valuation et Surveillance

### Ã‰valuation en Production

ğŸ“ Le modÃ¨le est Ã©valuÃ© Ã  l'aide de fichiers test.csv Ã©tiquetÃ©s manuellement. Ces fichiers servent Ã  mesurer la prÃ©cision et la robustesse des prÃ©dictions dans un environnement simulÃ© proche de la production. ğŸ“Š

### RÃ©entraÃ®nement

ğŸ”„ Les donnÃ©es collectÃ©es par FastAPI sont intÃ©grÃ©es dans MongoDB avec des mÃ©tadonnÃ©es comme l'heure, le rÃ©sultat des prÃ©dictions et les mesures associÃ©es.

- Airflow se charge de rÃ©cupÃ©rer ces donnÃ©es pour effectuer des Ã©tapes de transformation comme la standardisation via un scaler.
- Une fois prÃªtes, les donnÃ©es sont stockÃ©es pour un usage ultÃ©rieur dans les phases de rÃ©entraÃ®nement.
- Un nouveau modÃ¨le validÃ© est automatiquement rechargÃ© dans les pods concernÃ©s aprÃ¨s chaque itÃ©ration de rÃ©entraÃ®nement. âš¡

### Collecte et CI/CD

1. Airflow applique des pipelines CI/CD pour intÃ©grer des processus automatisÃ©s d'entraÃ®nement et de dÃ©ploiement.
2. Une surveillance continue permet de dÃ©tecter les anomalies dans les donnÃ©es et d'amÃ©liorer les performances des modÃ¨les au fil du temps. ğŸ› ï¸

### Surveillance des Performances

ğŸ“‰ Le stack Prometheus et Grafana permet de suivre :

- Les mÃ©triques issues de FastAPI, MongoDB.
- Les performances des ressources matÃ©rielles comme le CPU, la RAM et les disques.
- Les volumes de requÃªtes et les latences pour chaque service.
- Des alertes configurÃ©es pour dÃ©tecter les anomalies ou les baisses de performance. ğŸš¨

---

## Pods CrÃ©Ã©s

ğŸš€ Voici les pods actifs et leurs fonctions principales :

- **alertmanager-my-kube-prometheus-stack-alertmanager-0** : Supervision des alertes Prometheus.
- **my-kube-prometheus-stack-kube-state-metrics**
- **my-kube-prometheus-stack-operator**
- **my-kube-prometheus-stack-prometheus-node-exporter**
- **my-mongo-express**
- **my-mongodb**
- **prometheus-my-kube-prometheus-stack-prometheus**
- **app-streamlit-deployment-599d5b7b5f-xcckj** : Interface utilisateur pour la visualisation des prÃ©dictions.
![-](./images/Capture_streamlit.jpg)
- **curl-pod** : Outil de diagnostic pour tester les communications entre services.
- **model-deployment-674988f5c7-q8pw7** : DÃ©ploiement du modÃ¨le ML pour les prÃ©dictions.
![-](./images/Capture_fastapi_root.jpg)
![-](./images/Capture_fastapi_docs.jpg)
- **my-airflow-postgresql-0** : Base de donnÃ©es pour Apache Airflow.
- **my-airflow-redis-0** : Cache Redis utilisÃ© par Airflow.
- **my-airflow-scheduler-579d984dd7-9xh99** : Gestion des tÃ¢ches planifiÃ©es.
- **my-airflow-statsd-66699fb8b9-rxlg6** : Collecte des statistiques d'Airflow.
![-](./images/Capture_airflow_dags.jpg)
- **my-kube-prometheus-stack-grafana**
![-](./images/Capture_grafana.jpg)
---

## Architecture Globale

ğŸ¨ **SchÃ©ma de l'architecture technique** :

1. API FastAPI pour la gestion des prÃ©dictions et des utilisateurs.
# ğŸ“˜ Documentation de l'API FastAPI

Cette documentation dÃ©crit en dÃ©tail les endpoints disponibles dans l'application FastAPI, ainsi que leurs utilisations principales.

---

## ğŸ“‚ **RÃ©sumÃ© des Endpoints**

---

### ğŸ§‘â€ğŸ’» Gestion des utilisateurs

#### **POST /register**

- **RÃ©sumÃ© :** CrÃ©e un nouvel utilisateur.
- **Description :** Enregistre un utilisateur avec un mot de passe hachÃ© et retourne les dÃ©tails de l'utilisateur nouvellement crÃ©Ã©.
- **UtilitÃ© :** Ajout d'utilisateurs au systÃ¨me.

#### **POST /token**

- **RÃ©sumÃ© :** Obtenir un token d'accÃ¨s.
- **Description :** Permet aux utilisateurs existants de se connecter et de rÃ©cupÃ©rer un token JWT pour authentification.
- **UtilitÃ© :** Authentification et sÃ©curisation des endpoints.

---

### ğŸ”® ModÃ¨le de prÃ©diction

#### **POST /predict-test/**

- **RÃ©sumÃ© :** PrÃ©diction manuelle avec le modÃ¨le.
- **Description :** Effectue une prÃ©diction avec le modÃ¨le sans enregistrer les donnÃ©es dans la base MongoDB.
- **UtilitÃ© :** Tester le modÃ¨le localement sans archivage.

#### **POST /predict/**

- **RÃ©sumÃ© :** PrÃ©diction automatique et archivage.
- **Description :** Utilise le modÃ¨le pour prÃ©dire et sauvegarde les donnÃ©es (y compris la prÃ©diction) dans MongoDB.
- **UtilitÃ© :** OpÃ©ration complÃ¨te de prÃ©diction avec archivage.

#### **POST /Archivage/**

- **RÃ©sumÃ© :** Test d'archivage manuel.
- **Description :** InsÃ¨re directement une donnÃ©e dans MongoDB.
- **UtilitÃ© :** Test de l'archivage des donnÃ©es.

---

### âš™ï¸ Gestion des modÃ¨les

#### **GET /version**

- **RÃ©sumÃ© :** Obtenir les versions actuelles.
- **Description :** Retourne les versions du modÃ¨le et du standard scaler utilisÃ©s pour les prÃ©dictions.
- **UtilitÃ© :** VÃ©rification des versions dÃ©ployÃ©es.

#### **PUT /reload**

- **RÃ©sumÃ© :** Recharger le modÃ¨le depuis le cloud.
- **Description :** TÃ©lÃ©charge et charge la derniÃ¨re version du modÃ¨le et du scaler depuis Dagshub.
- **UtilitÃ© :** Mise Ã  jour des modÃ¨les.

---

### ğŸŒ Endpoints gÃ©nÃ©raux

#### **GET /**

- **RÃ©sumÃ© :** Page d'accueil HTML.
- **Description :** Affiche une page d'accueil simple avec un lien vers la documentation Swagger.
- **UtilitÃ© :** PrÃ©sentation et accÃ¨s rapide Ã  la documentation.

---

## â„¹ï¸ **Informations complÃ©mentaires**

### **BibliothÃ¨ques principales utilisÃ©es :**

- **FastAPI :** Framework principal pour l'API.
- **MongoDB :** Base de donnÃ©es utilisÃ©e pour stocker les mesures et les prÃ©dictions.
- **Dagshub et MLflow :** Outils pour gÃ©rer et versionner les modÃ¨les.
- **Prometheus :** Outil de monitoring via l'intÃ©gration Instrumentator.

---

### **Notes techniques :**

- L'authentification repose sur des tokens JWT gÃ©nÃ©rÃ©s avec un secret alÃ©atoire (non persistant entre redÃ©marrages).
- Les modÃ¨les et scalers sont chargÃ©s depuis un serveur MLflow dans Dagshub et sauvegardÃ©s localement en Pickle.

---

3. Pipeline CI/CD pour l'entraÃ®nement et le dÃ©ploiement automatisÃ©.
4. Monitoring centralisÃ© avec Grafana et Prometheus.
5. Orchestration des services avec Kubernetes et Helm.
6. Stockage des donnÃ©es avec MongoDB.

---

## Contributions

ğŸ¤ Les contributions sont les bienvenues ! Veuillez soumettre vos propositions via des pull requests sur le dÃ©pÃ´t GitHub.

---
## Repository Tree

    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
    â”œâ”€â”€ data
    â”‚Â Â  â”œâ”€â”€ external       <- Data from third party sources.
    â”‚Â Â  â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
    â”‚Â Â  â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
    â”‚Â Â  â””â”€â”€ raw            <- The original, immutable data dump.
    â”‚
    â”œâ”€â”€ logs               <- Logs from training and predicting
    â”‚
    â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
    â”‚
    â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    â”‚                         the creator's initials, and a short `-` delimited description, e.g.
    â”‚                         `1.0-jqp-initial-data-exploration`.
    â”‚
    â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
    â”‚
    â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    â”‚Â Â  â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
    â”‚
    â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    â”‚                         generated with `pip freeze > requirements.txt`
    â”‚
    â”œâ”€â”€ src                <- Source code for use in this project.
    â”‚Â Â  â”œâ”€â”€ __init__.py    <- Makes src a Python module
    â”‚   â”‚
    â”‚Â Â  â”œâ”€â”€ data           <- Scripts to download or generate data
    â”‚Â Â  â”‚Â Â  â””â”€â”€ make_dataset.py
    â”‚   â”‚
    â”‚Â Â  â”œâ”€â”€ features       <- Scripts to turn raw data into features for modeling
    â”‚Â Â  â”‚Â Â  â””â”€â”€ build_features.py
    â”‚   â”‚
    â”‚Â Â  â”œâ”€â”€ models         <- Scripts to train models and then use trained models to make
    â”‚   â”‚   â”‚                 predictions
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ predict_model.py
    â”‚Â Â  â”‚Â Â  â””â”€â”€ train_model.py
    â”‚   â”‚
    â”‚Â Â  â”œâ”€â”€ visualization  <- Scripts to create exploratory and results oriented visualizations
    â”‚Â Â  â”‚   â””â”€â”€ visualize.py
    â”‚Â Â  â””â”€â”€ config         <- Describe the parameters used in train_model.py and predict_model.py
---

## Bonus : Configuration des Redirections avec Traefik

### Routes ConfigurÃ©es

| Service       | URL de Redirection                   | Port  |
| ------------- | ------------------------------------ | ----- |
| **FastAPI**   | `https://inteva.hopto.org/api`       | 30001 |
| **Streamlit** | `https://inteva.hopto.org/streamlit` | 30002 |
| **Airflow**   | `https://inteva.hopto.org/airflow`   | 30003 |
| **Grafana**   | `https://inteva.hopto.org/grafana`   | 30004 |

---
