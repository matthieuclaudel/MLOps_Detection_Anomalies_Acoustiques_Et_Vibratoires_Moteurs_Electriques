D√©tection des anomalies acoustiques et vibratoires des moteurs √©lectriques
==============================
üéØ Ce projet vise √† automatiser la d√©tection d'anomalies acoustiques et vibratoires sur des moteurs √©lectriques √† la sortie d'une cha√Æne de production. L'objectif final est d'assurer un contr√¥le qualit√© pr√©cis et fiable tout en r√©duisant les co√ªts et les temps d'inspection. üöÄ

## Equipe projet

- Ludovic ANDRIEUX [GitHub](https://github.com/ludodo23)
- Matthieu CLAUDEL ([GitHub](https://github.com/matthieuclaudel) / [LinkedIn](http://www.linkedin.com/in/matthieu-claudel-8a927857))
- Adrien PINEL [GitHub](https://github.com/Adriencalvados) / [LinkedIn](www.linkedin.com/in/adrien-pinel-machine-learning-ingenieur)

## Architecture de l'application

![Architecture](./images/Archi.png)

## Table des Mati√®res

1. [Installation](#installation)
2. [Utilisation](#utilisation)
3. [Conteneurs Docker](#conteneurs-docker)
4. [Pr√©requis](#pr√©requis)
5. [Installation Kubernetes](#installation-kubernetes)
6. [Orchestration et Charts Helm](#orchestration-et-charts-helm)
7. [√âvaluation et Surveillance](#√©valuation-et-surveillance)
8. [Pods Cr√©√©s](#pods-cr√©√©s)
9. [Architecture Globale](#architecture-globale)
10. [Contributions](#contributions)
11. [Licence](#licence)
12. [Remerciements](#remerciements)
13. [R√©pertoires](#Repository-Tree)
14. [Configuration des Redirections avec Traefik](#Bonus-:-configuration-des-redirections-avec-traefik)
---

## Installation

### √âtapes d'installation

üîß **Cloner le d√©p√¥t GitHub :**

```bash
git clone https://github.com/matthieuclaudel/MLOps_Detection_Anomalies_Acoustiques_Et_Vibratoires_Moteurs_Electriques.git
```

üíª **Naviguer dans le r√©pertoire du projet :**

```bash
cd MLOps_Detection_Anomalies_Acoustiques_Et_Vibratoires_Moteurs_Electriques
```

üõ†Ô∏è **Cr√©er et activer un environnement virtuel Python :**

```bash
python3 -m venv venv
source venv/bin/activate
```

üì¶ **Installer les d√©pendances :**

```bash
pip install -r requirements.txt
```

---

## Utilisation

1. **Activer l'environnement virtuel :**

```bash
source venv/bin/activate
```

2. **Lancer l'application :**

```bash
python main.py
```

‚öôÔ∏è Fonction principale : Lors de son ex√©cution, le script main.py r√©cup√®re les donn√©es depuis DVC, cr√©e les ensembles X_test, X_train, Y_test, et Y_train dans les dossiers data, applique une transformation avec un standard scaler, entra√Æne un mod√®le, et le stocke dans Dagshub (MLflow Cloud). üöÄ

---

## Conteneurs Docker

### Conteneurs disponibles

üö¢ **Cr√©er un r√©seau de bridge :**

```bash
docker network create bridge_test_container
```

üõ†Ô∏è **API FastAPI (root URL : /api) :**

```bash
docker build -t adrien157/api -f docker/dockerfile.app_model .
docker push adrien157/api:latest
docker run --rm --name api --env-file .env -p 30001:30001 --network bridge_test_container adrien157/api:latest
```
![Architecture fastapi](./images/Diagramme-2025-01-06-2022.png)
üåê **Simulation de requ√™tes :**

```bash
docker build -t adrien157/simulation_request_model -f docker/dockerfile.app_simu .
docker push adrien157/simulation_request_model:latest
docker run --rm --name simu_request --env-file .env --network bridge_test_container adrien157/simulation_request_model:latest
```

üìä **Application Streamlit :**

```bash
docker build -t adrien157/app_streamlit -f docker/dockerfile.app_streamlit .
docker push adrien157/app_streamlit:latest
docker run --rm --name app_streamlit --env-file .env -p 8501:8501 --network bridge_test_container adrien157/app_streamlit:latest
```

---

## Pr√©requis

Pour utiliser ce projet, vous aurez besoin de :

- Un compte [DagsHub](https://dagshub.com/) üñ•Ô∏è
- Un compte [Docker](https://www.docker.com/) üê≥
- Une machine avec Debian install√© üñß
- Kubernetes K3S install√© ‚ò∏Ô∏è

---

## Installation Kubernetes

### √âtapes d'installation avec Helm

üî® **Installer Helm :**

```bash
curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
```

üìã **Configurer Kubernetes avec K3S :**

```bash
curl -sfL https://get.k3s.io | sh -
```

## Orchestration et Charts Helm

üìà **Prometheus Stack :**

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm install my-kube-prometheus-stack prometheus-community/kube-prometheus-stack --version 66.3.1
```

‚úàÔ∏è **Apache Airflow :**

```bash
helm repo add apache-airflow https://airflow.apache.org/
helm repo update
helm install my-airflow apache-airflow/airflow --version 1.15.0
```

**D√©ploiement de MongoDB (port 27017)**

Pour d√©ployer MongoDB et Mongo Express avec Helm, utilisez les commandes suivantes¬†:

```bash
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo add cowboysysop https://cowboysysop.github.io/charts/
helm repo update
helm install my-mongodb bitnami/mongodb --version 16.3.3 -f kubernetes/values-mongodb.yaml
helm install my-mongo-express cowboysysop/mongo-express --version 6.5.2 -f kubernetes/values-mongo-express.yaml
helm upgrade my-mongo-express cowboysysop/mongo-express --version 6.5.2 -f kubernetes/values-mongo-express.yaml
```

MongoDB est configur√© pour fonctionner avec les valeurs d√©finies dans le fichier `values-mongodb.yaml`.

## √âvaluation et Surveillance

### √âvaluation en Production

üìù Le mod√®le est √©valu√© √† l'aide de fichiers test.csv √©tiquet√©s manuellement. Ces fichiers servent √† mesurer la pr√©cision et la robustesse des pr√©dictions dans un environnement simul√© proche de la production. üìä

### R√©entra√Ænement

üîÑ Les donn√©es collect√©es par FastAPI sont int√©gr√©es dans MongoDB avec des m√©tadonn√©es comme l'heure, le r√©sultat des pr√©dictions et les mesures associ√©es.

- Airflow se charge de r√©cup√©rer ces donn√©es pour effectuer des √©tapes de transformation comme la standardisation via un scaler.
- Une fois pr√™tes, les donn√©es sont stock√©es pour un usage ult√©rieur dans les phases de r√©entra√Ænement.
- Un nouveau mod√®le valid√© est automatiquement recharg√© dans les pods concern√©s apr√®s chaque it√©ration de r√©entra√Ænement. ‚ö°

### Collecte et CI/CD

1. Airflow applique des pipelines CI/CD pour int√©grer des processus automatis√©s d'entra√Ænement et de d√©ploiement.
2. Une surveillance continue permet de d√©tecter les anomalies dans les donn√©es et d'am√©liorer les performances des mod√®les au fil du temps. üõ†Ô∏è

### Surveillance des Performances

üìâ Le stack Prometheus et Grafana permet de suivre :

- Les m√©triques issues de FastAPI, MongoDB.
- Les performances des ressources mat√©rielles comme le CPU, la RAM et les disques.
- Les volumes de requ√™tes et les latences pour chaque service.
- Des alertes configur√©es pour d√©tecter les anomalies ou les baisses de performance. üö®

---

## Pods Cr√©√©s

üöÄ Voici les pods actifs et leurs fonctions principales :

- **alertmanager-my-kube-prometheus-stack-alertmanager-0** : Supervision des alertes Prometheus.
- **my-kube-prometheus-stack-kube-state-metrics**
- **my-kube-prometheus-stack-operator**
- **my-kube-prometheus-stack-prometheus-node-exporter**
- **my-mongo-express**
![-](./images/Capture_mongoDB.jpg)
- **my-mongodb**
- **prometheus-my-kube-prometheus-stack-prometheus**
- **app-streamlit-deployment-599d5b7b5f-xcckj** : Interface utilisateur pour la visualisation des pr√©dictions.
![-](./images/Capture_streamlit.jpg)
- **curl-pod** : Outil de diagnostic pour tester les communications entre services.
- **model-deployment-674988f5c7-q8pw7** : D√©ploiement du mod√®le ML pour les pr√©dictions.
![-](./images/Capture_fastapi_root.jpg)
![-](./images/Capture_fastapi_docs.jpg)
- **my-airflow-postgresql-0** : Base de donn√©es pour Apache Airflow.
- **my-airflow-redis-0** : Cache Redis utilis√© par Airflow.
- **my-airflow-scheduler-579d984dd7-9xh99** : Gestion des t√¢ches planifi√©es.
- **my-airflow-statsd-66699fb8b9-rxlg6** : Collecte des statistiques d'Airflow.
![-](./images/ui_airflow.png)
- **my-kube-prometheus-stack-grafana**
![-](./images/Capture_grafana.jpg)
---

## Architecture Globale

üé® **Sch√©ma de l'architecture technique** :

1. API FastAPI pour la gestion des pr√©dictions et des utilisateurs.
# üìò Documentation de l'API FastAPI

Cette documentation d√©crit en d√©tail les endpoints disponibles dans l'application FastAPI, ainsi que leurs utilisations principales.

---

## üìÇ **R√©sum√© des Endpoints**

---

### üßë‚Äçüíª Gestion des utilisateurs

#### **POST /register**

- **R√©sum√© :** Cr√©e un nouvel utilisateur.
- **Description :** Enregistre un utilisateur avec un mot de passe hach√© et retourne les d√©tails de l'utilisateur nouvellement cr√©√©.
- **Utilit√© :** Ajout d'utilisateurs au syst√®me.

#### **POST /token**

- **R√©sum√© :** Obtenir un token d'acc√®s.
- **Description :** Permet aux utilisateurs existants de se connecter et de r√©cup√©rer un token JWT pour authentification.
- **Utilit√© :** Authentification et s√©curisation des endpoints.

---

### üîÆ Mod√®le de pr√©diction

#### **POST /predict-test/**

- **R√©sum√© :** Pr√©diction manuelle avec le mod√®le.
- **Description :** Effectue une pr√©diction avec le mod√®le sans enregistrer les donn√©es dans la base MongoDB.
- **Utilit√© :** Tester le mod√®le localement sans archivage.

#### **POST /predict/**

- **R√©sum√© :** Pr√©diction automatique et archivage.
- **Description :** Utilise le mod√®le pour pr√©dire et sauvegarde les donn√©es (y compris la pr√©diction) dans MongoDB.
- **Utilit√© :** Op√©ration compl√®te de pr√©diction avec archivage.

#### **POST /Archivage/**

- **R√©sum√© :** Test d'archivage manuel.
- **Description :** Ins√®re directement une donn√©e dans MongoDB.
- **Utilit√© :** Test de l'archivage des donn√©es.

---

### ‚öôÔ∏è Gestion des mod√®les

#### **GET /version**

- **R√©sum√© :** Obtenir les versions actuelles.
- **Description :** Retourne les versions du mod√®le et du standard scaler utilis√©s pour les pr√©dictions.
- **Utilit√© :** V√©rification des versions d√©ploy√©es.

#### **PUT /reload**

- **R√©sum√© :** Recharger le mod√®le depuis le cloud.
- **Description :** T√©l√©charge et charge la derni√®re version du mod√®le et du scaler depuis Dagshub.
- **Utilit√© :** Mise √† jour des mod√®les.

---

### üåê Endpoints g√©n√©raux

#### **GET /**

- **R√©sum√© :** Page d'accueil HTML.
- **Description :** Affiche une page d'accueil simple avec un lien vers la documentation Swagger.
- **Utilit√© :** Pr√©sentation et acc√®s rapide √† la documentation.

---

## ‚ÑπÔ∏è **Informations compl√©mentaires**

### **Biblioth√®ques principales utilis√©es :**

- **FastAPI :** Framework principal pour l'API.
- **MongoDB :** Base de donn√©es utilis√©e pour stocker les mesures et les pr√©dictions.
- **Dagshub et MLflow :** Outils pour g√©rer et versionner les mod√®les.
- **Prometheus :** Outil de monitoring via l'int√©gration Instrumentator.

---

### **Notes techniques :**

- L'authentification repose sur des tokens JWT g√©n√©r√©s avec un secret al√©atoire (non persistant entre red√©marrages).
- Les mod√®les et scalers sont charg√©s depuis un serveur MLflow dans Dagshub et sauvegard√©s localement en Pickle.

---

3. Pipeline CI/CD pour l'entra√Ænement et le d√©ploiement automatis√©.
4. Monitoring centralis√© avec Grafana et Prometheus.
5. Orchestration des services avec Kubernetes et Helm.
6. Stockage des donn√©es avec MongoDB.

---

## Contributions

ü§ù Les contributions sont les bienvenues ! Veuillez soumettre vos propositions via des pull requests sur le d√©p√¥t GitHub.

---
## Repository Tree

    ‚îú‚îÄ‚îÄ LICENSE
    ‚îú‚îÄ‚îÄ README.md          <- The top-level README for developers using this project.
    ‚îú‚îÄ‚îÄ airflow
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ dags           <- Dags scripts used in the solution.
    ‚îÇ¬†¬†  ¬†¬† ‚îî‚îÄ‚îÄ DAG_kube.py
    ‚îÇ¬†¬†  ¬†¬† ‚îî‚îÄ‚îÄ DAG_raw_scale.py    
    ‚îÇ
    ‚îú‚îÄ‚îÄ data
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ raw            <- Original, immutable, temporarily generated data dump.
    ‚îÇ
    ‚îú‚îÄ‚îÄ docker
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ load_model     <- Dockerfile and script to generate the image matthieu247/load_data
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ load_data.py
    ‚îÇ   ‚îÇ    
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ raw_data       <- Dockerfile and script to generate the image ludodo/mlops-dst-project-get-from-mongo:latest‚îÇ
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ raw_data.py
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ register_model <- Dockerfile and script to generate the image matthieu247/register
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ register_model.py
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ train_model    <- Dockerfile and script to generate the image matthieu247/train_accoustic_model
    ‚îÇ       ‚îî‚îÄ‚îÄ train_model.py
    ‚îÇ       
    ‚îú‚îÄ‚îÄ images             <- Figures to be used in reporting as HTML, PDF, LaTeX, etc.
    ‚îÇ
    ‚îú‚îÄ‚îÄ kubernetes         <- This directory contains all the yaml manifests to deploy the solution and in particular the pv, pvc 
    ‚îÇ                         and the airflow_values.yaml manifest to create the data persistence
    ‚îÇ
    ‚îú‚îÄ‚îÄ models             <- ....
    ‚îÇ
    ‚îú‚îÄ‚îÄ notebooks          <- Jupyter notebooks created during the modeling research phase.
    ‚îÇ
    ‚îú‚îÄ‚îÄ reports         
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ figures        <- Figures to be used in reporting as HTML, PDF, LaTeX, etc.
    ‚îÇ
    ‚îÇ
    ‚îú‚îÄ‚îÄ src                <- Source code for use in this project.
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ main.py        <- Makes src a Python module
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ apps           <- Scripts for application
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ streamlit
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pages
    ‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ 1_Data_Visualizer.py
    ‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ 2_Reduction_dimension.py    
    ‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ 3_Model.py 
    ‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ 4_Test_prediction.py
    ‚îÇ   ‚îÇ   ‚îÇ
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app_model.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app_model_models.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ app_simulation.py    
    ‚îÇ   ‚îÇ       
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ data           <- Scripts to download or generate data
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ make_dataset.py
    ‚îÇ¬†¬† ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ features       <- Scripts to turn raw data into features for modeling
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ build_features.py
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ models         <- Scripts to train models and then use trained models to make predictions
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict_model.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_model.py                     
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ main.py
    ‚îÇ   
    ‚îú‚îÄ‚îÄ tests          <- Scripts to create exploratory and results oriented visualizations
    ‚îÇ¬†¬† ‚îÇ  
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ test_data.py    
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ test_features.py  
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ test_models.py 
    ‚îÇ
    ‚îî‚îÄ‚îÄ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
                              generated with `pip freeze > requirements.txt`
---

## Bonus : Configuration des Redirections avec Traefik

### Routes Configur√©es

| Service       | URL de Redirection                   | Port  |
| ------------- | ------------------------------------ | ----- |
| **FastAPI**   | `https://inteva.hopto.org/api`       | 30001 |
| **Streamlit** | `https://inteva.hopto.org/streamlit` | 30002 |
| **Airflow**   | `https://inteva.hopto.org/airflow`   | 30003 |
| **Grafana**   | `https://inteva.hopto.org/grafana`   | 30004 |

---
