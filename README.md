DÃ©tection des anomalies acoustiques et vibratoires des moteurs Ã©lectriques
==============================

L'objectif de ce projet est d'automatiser la dÃ©tection d'anomalies sur des moteurs Ã©lectriques Ã  la sortie d'une chaÃ®ne de production.

## Equipe projet

- Ludovic ANDRIEUX [GitHub](https://github.com/ludodo23)
- Matthieu CLAUDEL ([GitHub](https://github.com/matthieuclaudel) / [LinkedIn](http://www.linkedin.com/in/matthieu-claudel-8a927857))
- Adrien PINEL [GitHub](https://github.com/Adriencalvados) / [LinkedIn](www.linkedin.com/in/adrien-pinel-machine-learning-ingenieur)
- Harold MOUKALA MITATI [GitHub](https://github.com/Ngulumanua)

## Architecture de l'application

![Architecture](./data/Archi.png)

## Repository Tree

    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
    â”œâ”€â”€ data
    â”‚Â Â  â”œâ”€â”€ external       <- Data from third party sources.
    â”‚Â Â  â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
    â”‚Â Â  â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
    â”‚Â Â  â””â”€â”€ raw            <- The original, immutable data dump.
    â”‚
    â”œâ”€â”€ logs               <- Logs from training and predicting
    â”‚
    â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
    â”‚
    â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    â”‚                         the creator's initials, and a short `-` delimited description, e.g.
    â”‚                         `1.0-jqp-initial-data-exploration`.
    â”‚
    â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
    â”‚
    â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    â”‚Â Â  â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
    â”‚
    â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    â”‚                         generated with `pip freeze > requirements.txt`
    â”‚
    â”œâ”€â”€ src                <- Source code for use in this project.
    â”‚Â Â  â”œâ”€â”€ __init__.py    <- Makes src a Python module
    â”‚   â”‚
    â”‚Â Â  â”œâ”€â”€ data           <- Scripts to download or generate data
    â”‚Â Â  â”‚Â Â  â””â”€â”€ make_dataset.py
    â”‚   â”‚
    â”‚Â Â  â”œâ”€â”€ features       <- Scripts to turn raw data into features for modeling
    â”‚Â Â  â”‚Â Â  â””â”€â”€ build_features.py
    â”‚   â”‚
    â”‚Â Â  â”œâ”€â”€ models         <- Scripts to train models and then use trained models to make
    â”‚   â”‚   â”‚                 predictions
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ predict_model.py
    â”‚Â Â  â”‚Â Â  â””â”€â”€ train_model.py
    â”‚   â”‚
    â”‚Â Â  â”œâ”€â”€ visualization  <- Scripts to create exploratory and results oriented visualizations
    â”‚Â Â  â”‚   â””â”€â”€ visualize.py
    â”‚Â Â  â””â”€â”€ config         <- Describe the parameters used in train_model.py and predict_model.py

--------

## Installation
## ðŸŽ¬ Getting Started for Developers

```shell
git clone https://github.com/matthieuclaudel/MLOps_Detection_Anomalies_Acoustiques_Et_Vibratoires_Moteurs_Electriques
```


---

## Table des MatiÃ¨res

1. [Installation](#installation)
2. [Utilisation](#utilisation)
3. [Conteneurs Docker](#conteneurs-docker)
4. [PrÃ©requis](#prÃ©requis)
5. [Installation Kubernetes](#installation-kubernetes)
6. [Orchestration et Charts Helm](#orchestration-et-charts-helm)
7. [Configuration des Redirections avec Traefik](#configuration-des-redirections-avec-traefik)
8. [Ã‰valuation et Surveillance](#Ã©valuation-et-surveillance)
9. [Pods CrÃ©Ã©s](#pods-crÃ©Ã©s)
10. [Architecture Globale](#architecture-globale)
11. [Contributions](#contributions)
12. [Licence](#licence)
13. [Remerciements](#remerciements)

---

## Installation

### Ã‰tapes d'installation

ðŸ”§ **Cloner le dÃ©pÃ´t GitHub :**

```bash
git clone https://github.com/matthieuclaudel/MLOps_Detection_Anomalies_Acoustiques_Et_Vibratoires_Moteurs_Electriques.git
```

ðŸ’» **Naviguer dans le rÃ©pertoire du projet :**

```bash
cd MLOps_Detection_Anomalies_Acoustiques_Et_Vibratoires_Moteurs_Electriques
```

ðŸ› ï¸ **CrÃ©er et activer un environnement virtuel Python :**

```bash
python3 -m venv venv
source venv/bin/activate
```

ðŸ“¦ **Installer les dÃ©pendances :**

```bash
pip install -r requirements.txt
```

---

## Utilisation

1. **Activer l'environnement virtuel :**

```bash
source venv/bin/activate
```

2. **Lancer l'application :**

```bash
python main.py
```

âš™ï¸ **Fonction principale :** Lors de son exÃ©cution, le script `main.py` rÃ©cupÃ¨re les donnÃ©es depuis DVC, crÃ©e les ensembles X\_test, X\_train, Y\_test, et Y\_train dans les dossiers `data`, applique une transformation avec un standard scaler, entraÃ®ne un modÃ¨le, et le stocke dans Dagshub (MLflow Cloud). ðŸš€

3. **AccÃ©der Ã  l'application via votre navigateur :**

Par exemple : `http://localhost:3000`. ðŸŒ

---

## Conteneurs Docker

### Conteneurs disponibles

ðŸš¢ **CrÃ©er un rÃ©seau de bridge :**

```bash
docker network create bridge_test_container
```

ðŸ› ï¸ **API FastAPI (root URL : /api) :**

```bash
docker build -t adrien157/api -f docker/dockerfile.app_model .
docker push adrien157/api:latest
docker run --rm --name api --env-file .env -p 30001:30001 --network bridge_test_container adrien157/api:latest
```
![Architecture fastapi](./images/Diagramme-2025-01-06-2022.png)
ðŸŒ **Simulation de requÃªtes :**

```bash
docker build -t adrien157/simulation_request_model -f docker/dockerfile.app_simu .
docker push adrien157/simulation_request_model:latest
docker run --rm --name simu_request --env-file .env --network bridge_test_container adrien157/simulation_request_model:latest
```

ðŸ“Š **Application Streamlit :**

```bash
docker build -t adrien157/app_streamlit -f docker/dockerfile.app_streamlit .
docker push adrien157/app_streamlit:latest
docker run --rm --name app_streamlit --env-file .env -p 8501:8501 --network bridge_test_container adrien157/app_streamlit:latest
```

---

## PrÃ©requis

Pour utiliser ce projet, vous aurez besoin de :

- Un compte [DagsHub](https://dagshub.com/) ðŸ–¥ï¸
- Un compte [Docker](https://www.docker.com/) ðŸ³
- Une machine avec Debian installÃ© ðŸ–§
- Kubernetes K3S installÃ© â˜¸ï¸

---

## Installation Kubernetes

### Ã‰tapes d'installation avec Helm

ðŸ”¨ **Installer Helm :**

```bash
curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
```

ðŸ“‹ **Configurer Kubernetes avec K3S :**

```bash
curl -sfL https://get.k3s.io | sh -
```

ðŸš€ **DÃ©ployer des applications avec Helm :**

```bash
helm repo add stable https://charts.helm.sh/stable
helm repo update
helm install my-app stable/chart-name
```

---

## Orchestration et Charts Helm

### Exemple de dÃ©ploiement avec Minikube

ðŸŒ **Activer les ports nÃ©cessaires :**

```bash
minikube service multi-port-service-public --url
```

Ou dÃ©marrer Minikube avec des ports spÃ©cifiques :

```bash
minikube start --driver=docker --ports 30000:30000 --ports 30001:30001 \
--ports 30002:30002 --ports 30003:30003 --ports 30004:30004 \
--ports 8081:8081 --ports 30005:30005 --ports 27017:27017
```

ðŸ“ˆ **Prometheus Stack :**

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm install my-kube-prometheus-stack prometheus-community/kube-prometheus-stack --version 66.3.1
```

âœˆï¸ **Apache Airflow :**

```bash
helm repo add apache-airflow https://airflow.apache.org/
helm repo update
helm install my-airflow apache-airflow/airflow --version 1.15.0
```

---

## Configuration des Redirections avec Traefik

### Routes ConfigurÃ©es

| Service       | URL de Redirection                   | Port  |
| ------------- | ------------------------------------ | ----- |
| **FastAPI**   | `https://inteva.hopto.org/api`       | 30001 |
| **Streamlit** | `https://inteva.hopto.org/streamlit` | 30002 |
| **Airflow**   | `https://inteva.hopto.org/airflow`   | 30003 |
| **Grafana**   | `https://inteva.hopto.org/grafana`   | 30004 |

---

## Ã‰valuation et Surveillance

### Ã‰valuation en Production

ðŸ“ Le modÃ¨le est Ã©valuÃ© Ã  l'aide de fichiers test.csv Ã©tiquetÃ©s manuellement. Ces fichiers servent Ã  mesurer la prÃ©cision et la robustesse des prÃ©dictions dans un environnement simulÃ© proche de la production. ðŸ“Š

### RÃ©entraÃ®nement

ðŸ”„ Les donnÃ©es collectÃ©es par FastAPI sont intÃ©grÃ©es dans MongoDB avec des mÃ©tadonnÃ©es comme l'heure, le rÃ©sultat des prÃ©dictions et les mesures associÃ©es.

- Airflow se charge de rÃ©cupÃ©rer ces donnÃ©es pour effectuer des Ã©tapes de transformation comme la standardisation via un scaler.
- Une fois prÃªtes, les donnÃ©es sont stockÃ©es dans InfluxDB pour un usage ultÃ©rieur dans les phases de rÃ©entraÃ®nement.
- Un nouveau modÃ¨le validÃ© est automatiquement rechargÃ© dans les pods concernÃ©s aprÃ¨s chaque itÃ©ration de rÃ©entraÃ®nement. âš¡

### Collecte et CI/CD

1. Airflow applique des pipelines CI/CD pour intÃ©grer des processus automatisÃ©s d'entraÃ®nement et de dÃ©ploiement.
2. Une surveillance continue permet de dÃ©tecter les anomalies dans les donnÃ©es et d'amÃ©liorer les performances des modÃ¨les au fil du temps. ðŸ› ï¸

### Surveillance des Performances

ðŸ“‰ Le stack Prometheus et Grafana permet de suivre :

- Les mÃ©triques issues de FastAPI, MongoDB et InfluxDB.
- Les performances des ressources matÃ©rielles comme le CPU, la RAM et les disques.
- Les volumes de requÃªtes et les latences pour chaque service.
- Des alertes configurÃ©es pour dÃ©tecter les anomalies ou les baisses de performance. ðŸš¨

---

## Pods CrÃ©Ã©s

ðŸš€ Voici les pods actifs et leurs fonctions principales :

- **alertmanager-my-kube-prometheus-stack-alertmanager-0** : Supervision des alertes Prometheus.
- **app-streamlit-deployment-599d5b7b5f-xcckj** : Interface utilisateur pour la visualisation des prÃ©dictions.
![-](./images/Capture_streamlit.jpg)

- **curl-pod** : Outil de diagnostic pour tester les communications entre services.
- **model-deployment-674988f5c7-q8pw7** : DÃ©ploiement du modÃ¨le ML pour les prÃ©dictions.
![-](./images/Capture_fastapi_root.jpg)
![-](./images/Capture_fastapi_docs.jpg)

- **my-airflow-postgresql-0** : Base de donnÃ©es pour Apache Airflow.
- **my-airflow-redis-0** : Cache Redis utilisÃ© par Airflow.
- **my-airflow-scheduler-579d984dd7-9xh99** : Gestion des tÃ¢ches planifiÃ©es.
- **my-airflow-statsd-66699fb8b9-rxlg6** : Collecte des statistiques d'Airflow.
![-](./images/Capture_airflow_dags.jpg)
- **grafana**
![-](./images/Capture_grafana.jpg)
---

## Architecture Globale

ðŸŽ¨ **SchÃ©ma de l'architecture technique** :

1. API FastAPI pour la gestion des prÃ©dictions et des utilisateurs.
2. Pipeline CI/CD pour l'entraÃ®nement et le dÃ©ploiement automatisÃ©.
3. Monitoring centralisÃ© avec Grafana et Prometheus.
4. Orchestration des services avec Kubernetes et Helm.
5. Stockage des donnÃ©es avec MongoDB et InfluxDB.

---

## Contributions

ðŸ¤ Les contributions sont les bienvenues ! Veuillez soumettre vos propositions via des pull requests sur le dÃ©pÃ´t GitHub.

---